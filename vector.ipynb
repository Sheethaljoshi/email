{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore(id='vs_0yhzHPvJzcQT66OJ23HtNfRp', created_at=1717766228, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=0, total=0), last_active_at=1717766228, metadata={}, name='GRITAE2', object='vector_store', status='completed', usage_bytes=0, expires_after=None, expires_at=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "vector_store = client.beta.vector_stores.create(\n",
    "  name=\"GRITAE2\"\n",
    ")\n",
    "print(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-MUUy46T4HmjR1ylBCit5vpF5', created_at=1717765253, last_error=None, object='vector_store.file', status='completed', usage_bytes=653708, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-MyyxS1VHkBQPQuJ6THPYH94S', created_at=1717765252, last_error=None, object='vector_store.file', status='completed', usage_bytes=720855, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-DBWXLsIg8aNax7I7e8sfsq4l', created_at=1717765251, last_error=None, object='vector_store.file', status='completed', usage_bytes=692515, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-2aXiNodOOINi9D0f5TCgPEHw', created_at=1717765251, last_error=None, object='vector_store.file', status='completed', usage_bytes=653941, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-CwVkSX9hlB1BxxyesoUbkg9U', created_at=1717765250, last_error=None, object='vector_store.file', status='completed', usage_bytes=711640, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-UMW3YLtChT4zvqivnjwzTO6D', created_at=1717765249, last_error=None, object='vector_store.file', status='completed', usage_bytes=726462, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-Xs3FJ6raKSQ7LSezxWSq2sDp', created_at=1717765248, last_error=None, object='vector_store.file', status='completed', usage_bytes=681938, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-NDYEdT0ZRRYOxdNpR5GPKws7', created_at=1717765247, last_error=None, object='vector_store.file', status='completed', usage_bytes=662617, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-VR8jCgSHFWmY63JSn2n7oWkT', created_at=1717765246, last_error=None, object='vector_store.file', status='completed', usage_bytes=721496, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-Mekxe2zazNQplX4csKSHZljt', created_at=1717765245, last_error=None, object='vector_store.file', status='completed', usage_bytes=715872, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-NCOWOKjEDqbF10EUuJb4q32B', created_at=1717765244, last_error=None, object='vector_store.file', status='completed', usage_bytes=674354, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-vT6vYy49aVk8TBhGU3WNy28p', created_at=1717765244, last_error=None, object='vector_store.file', status='completed', usage_bytes=726387, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-5b3ajpvdP0cjVOMxk3rRpfeh', created_at=1717765243, last_error=None, object='vector_store.file', status='completed', usage_bytes=742453, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-GvJLfj5drq1YhbU69Nedk1E0', created_at=1717765242, last_error=None, object='vector_store.file', status='completed', usage_bytes=664153, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-rtnL23xzzQdx9AdErnTPiT84', created_at=1717765242, last_error=None, object='vector_store.file', status='completed', usage_bytes=668556, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-V093G0WEVVGhAe9KCpGJFgbE', created_at=1717765240, last_error=None, object='vector_store.file', status='completed', usage_bytes=692026, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-2Z5jpTepGefpsifvCLTlsk3w', created_at=1717765240, last_error=None, object='vector_store.file', status='completed', usage_bytes=678351, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-22opSkPj2Zegq4NgTEVod7hm', created_at=1717765238, last_error=None, object='vector_store.file', status='completed', usage_bytes=726102, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-U7apK85tNFI6JCcUDvKVc81Z', created_at=1717765238, last_error=None, object='vector_store.file', status='completed', usage_bytes=719200, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}), VectorStoreFile(id='file-vE54vNiuNV4dk34Reb8uvvHm', created_at=1717765237, last_error=None, object='vector_store.file', status='completed', usage_bytes=720296, vector_store_id='vs_VwMZZPLE2n0cmHr0oqSgFzGL', chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}})], object='list', first_id='file-MUUy46T4HmjR1ylBCit5vpF5', last_id='file-vE54vNiuNV4dk34Reb8uvvHm', has_more=True)\n"
     ]
    }
   ],
   "source": [
    "vector_store_files = client.beta.vector_stores.files.list(\n",
    "  vector_store_id=\"vs_VwMZZPLE2n0cmHr0oqSgFzGL\"\n",
    ")\n",
    "print(vector_store_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vector_store_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_fWOdEbV2lJMhJ6kz6RyPpkmk', created_at=1717772128, description=None, instructions='You have been given HTML documents of case studies of projects done for different companies in the past. You will be provided the about page of a website of a company that deals in a specific field of IT servicing. You are to provide the name of the company that corresponds to the most similar case study, and also 3 reasons why that case study is worth going through.', metadata={}, model='gpt-4-turbo', name='GRITAE', object='assistant', tools=[FileSearchTool(type='file_search')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_VwMZZPLE2n0cmHr0oqSgFzGL'])), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You have been given HTML documents of case studies of projects done for different companies in the past. You will be provided the about page of a website of a company that deals in a specific field of IT servicing. You are to provide the name of the company that corresponds to the most similar case study, and also 3 reasons why that case study is worth going through.\",\n",
    "    name=\"GRITAE\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tool_resources={\n",
    "    \"file_search\": {\n",
    "      \"vector_store_ids\": [\"vs_VwMZZPLE2n0cmHr0oqSgFzGL\"]\n",
    "    }\n",
    "  }\n",
    ")\n",
    "print(my_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_EdCxX673x1nFzLPZhlD3yUZW', created_at=1717768602, description=None, instructions='', metadata={}, model='gpt-4o', name='GRITAE2', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"\",\n",
    "    name=\"GRITAE2\",\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "print(my_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=\"asst_EdCxX673x1nFzLPZhlD3yUZW\",\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You will be given a list of endpoints of a particular website. You are to provide back the website link that is most likely to be the about page of the website. Return nothing but the link. The list is as follows: \"+str()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "thread = client.beta.threads.create()\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=\"asst_fWOdEbV2lJMhJ6kz6RyPpkmk\",\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You have been given HTML documents of case studies of projects done for different companies in the past. You have also been provided the about page of a website of a prospect that is \"+ \"www.loops.so/\" + \"You are to provide website of the company that is most similar to the prospect in terms of being in the same domain, and also 3 reasons why it would be beneficial for the prospect to look through the case study. Each reason must have 50 words each and must highlight the technological solution given to the company. Provide the response in json format {\\\"link\\\":\\\"www.fundrise.com\\\", \\\"content\\\":\\\"[\\\"point1\\\",\\\"point2\\\",\\\"point3\\\"]\\\"}. DO NOT GIVE A SINGLE WORD EXCEPT FOR THE JSON, make it columnar structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"link\":\"www.fundrise.com\", \"content\":[\"Implementing Intercom's AI-powered platform helped Fundrise manage their support by automating frequently asked questions, reducing staff workload and improving response time for complex queries. This technological solution can help Loops manage large volumes of support queries efficiently.【5:0†source】\", \"Fundrise leveraged the Fin AI Agent to handle more than 50% of their total support cases, allowing their Investor Relations team to focus on high-complexity issues. Loops could benefit from a similar setup to optimize their support operations and enhance customer satisfaction【5:0†source】\", \"By integrating Team Inbox and Articles within Intercom, Fundrise ensured that their support process was streamlined and that users could easily find answers to common issues. Adopting these technologies can help Loops provide more accessible support content, improving the overall user experience【5:0†source】\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "if run.status == \"completed\":\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        link = messages.data[0].content[0].text.value\n",
    "        print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
